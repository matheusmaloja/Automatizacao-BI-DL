{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4UpvjMYNUMjLa4iexL02Y"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA8JqAv_GT2K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "from pandas.errors import EmptyDataError\n",
        "\n",
        "# 1. Autenticação\n",
        "filename = 'autenticacao' #documento de autenticação do google\n",
        "scopes = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(filename, scopes)\n",
        "client = gspread.authorize(credentials)\n",
        "\n",
        "# Montar o Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def process_and_update_sheet(folder_path, sheet_name, name_replacements, key_cols_specific=None):\n",
        "    \"\"\"\n",
        "    Processa arquivos CSV de uma pasta, limpa os dados e atualiza uma planilha do Google Sheets.\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Caminho da pasta onde os arquivos CSV estão localizados.\n",
        "        sheet_name (str): Nome da planilha no Google Sheets a ser atualizada.\n",
        "        name_replacements (dict): Dicionário para substituir os nomes de arquivos por nomes de artistas.\n",
        "        key_cols_specific (list, optional): Lista de colunas a serem usadas como chaves de unicidade\n",
        "                                            para este tipo específico de dados.\n",
        "                                            Se None, a lógica padrão será usada.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Processando e atualizando a planilha: {sheet_name} ---\")\n",
        "\n",
        "    try:\n",
        "        spreadsheet = client.open(sheet_name)\n",
        "        worksheet = spreadsheet.worksheet(\"Sheet1\")\n",
        "        df_existente = get_as_dataframe(worksheet).dropna(how='all')\n",
        "        print(f\"Dados existentes na planilha '{sheet_name}' carregados. Linhas: {len(df_existente)}\")\n",
        "\n",
        "    except gspread.exceptions.SpreadsheetNotFound:\n",
        "        print(f\"Aviso: Planilha '{sheet_name}' não encontrada. Criando uma nova.\")\n",
        "        spreadsheet = client.create(sheet_name)\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        df_existente = pd.DataFrame()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao abrir ou ler a planilha '{sheet_name}': {e}\")\n",
        "        return\n",
        "\n",
        "    arquivos_csv = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "    lista_de_dataframes = []\n",
        "\n",
        "    for arquivo in arquivos_csv:\n",
        "        caminho_arquivo = os.path.join(folder_path, arquivo)\n",
        "        # print(f\"Lendo arquivo: {arquivo}\") # Removido para um log mais limpo se muitos arquivos\n",
        "\n",
        "        try:\n",
        "            if os.path.getsize(caminho_arquivo) == 0:\n",
        "                print(f\"Aviso: o arquivo {arquivo} está vazio e foi ignorado.\")\n",
        "                continue\n",
        "\n",
        "            df = pd.read_csv(caminho_arquivo)\n",
        "            if not df.empty:\n",
        "                df['nome_arquivo_origem'] = arquivo.replace('.csv', '')\n",
        "                lista_de_dataframes.append(df)\n",
        "            else:\n",
        "                print(f\"  Aviso: O arquivo '{arquivo}' foi lido, mas resultou em um DataFrame vazio. Ignorado.\")\n",
        "\n",
        "        except EmptyDataError:\n",
        "            print(f\"Aviso: o arquivo {arquivo} está vazio ou sem colunas e foi ignorado.\")\n",
        "        except pd.errors.ParserError as pe:\n",
        "            print(f\"Erro de parsing no arquivo {arquivo}: {pe}. Ignorado.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Erro inesperado ao ler {arquivo}: {e}. Ignorado.\")\n",
        "\n",
        "    if not lista_de_dataframes:\n",
        "        print(f\"Nenhum arquivo CSV válido encontrado na pasta: {folder_path}. Abortando atualização da planilha.\")\n",
        "        return\n",
        "\n",
        "    # --- Início da correção da UnboundLocalError ---\n",
        "    # Define as colunas-chave com base nos dados e na especificidade opcional ANTES da lógica de df_existente\n",
        "    key_columns = []\n",
        "    if key_cols_specific:\n",
        "        key_columns = key_cols_specific\n",
        "    elif 'nome_arquivo_origem' in lista_de_dataframes[0].columns and 'date' in lista_de_dataframes[0].columns:\n",
        "        key_columns = ['nome_arquivo_origem', 'date']\n",
        "    elif 'nome_arquivo_origem' in lista_de_dataframes[0].columns and 'date_added' in lista_de_dataframes[0].columns and 'title' in lista_de_dataframes[0].columns:\n",
        "        key_columns = ['nome_arquivo_origem', 'title', 'date_added']\n",
        "    elif 'nome_arquivo_origem' in lista_de_dataframes[0].columns and 'release_date' in lista_de_dataframes[0].columns and 'song' in lista_de_dataframes[0].columns:\n",
        "        key_columns = ['nome_arquivo_origem', 'song', 'release_date']\n",
        "    elif 'nome_arquivo_origem' in lista_de_dataframes[0].columns:\n",
        "         key_columns = ['nome_arquivo_origem'] # Fallback\n",
        "    else:\n",
        "        print(\"Erro: Não foi possível determinar as colunas-chave para identificação de duplicatas. Verifique a estrutura dos CSVs e/ou defina 'key_cols_specific'. Abortando.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Chaves de comparação para duplicatas: {key_columns}\") # DEBUG\n",
        "\n",
        "    tabela_nova = pd.concat(lista_de_dataframes, ignore_index=True)\n",
        "\n",
        "    # Conversão de datas: feita antes da comparação de chaves\n",
        "    if 'date' in tabela_nova.columns:\n",
        "        tabela_nova['date'] = tabela_nova['date'].astype(str)\n",
        "        tabela_nova['date'] = pd.to_datetime(tabela_nova['date'], errors='coerce').dt.date\n",
        "    if 'release_date' in tabela_nova.columns:\n",
        "        tabela_nova['release_date'] = tabela_nova['release_date'].astype(str)\n",
        "        tabela_nova['release_date'] = pd.to_datetime(tabela_nova['release_date'], errors='coerce').dt.date\n",
        "    if 'date_added' in tabela_nova.columns:\n",
        "        tabela_nova['date_added'] = tabela_nova['date_added'].astype(str)\n",
        "        tabela_nova['date_added'] = pd.to_datetime(tabela_nova['date_added'], errors='coerce').dt.date\n",
        "\n",
        "    # Criação da coluna 'artista'\n",
        "    if 'nome_arquivo_origem' in tabela_nova.columns:\n",
        "        tabela_nova['artista'] = tabela_nova['nome_arquivo_origem'].replace(name_replacements)\n",
        "    else:\n",
        "        print(\"Aviso: Coluna 'nome_arquivo_origem' não encontrada na tabela consolidada. Não foi possível renomear artistas. Abortando.\")\n",
        "        return\n",
        "\n",
        "    # Garante que as colunas chave existam em ambos os DataFrames (para evitar KeyError no df_existente)\n",
        "    for col in key_columns:\n",
        "        if col not in tabela_nova.columns:\n",
        "            print(f\"Erro: Coluna '{col}' necessária para a chave de duplicidade não encontrada na tabela_nova. Abortando.\")\n",
        "            return\n",
        "        if col not in df_existente.columns and not df_existente.empty: # Só verifica se df_existente NÃO está vazia\n",
        "            print(f\"Erro: Coluna '{col}' necessária para a chave de duplicidade não encontrada na planilha existente ('{sheet_name}'). Adicione a coluna manualmente à sua planilha do Google Sheets. Abortando.\")\n",
        "            return\n",
        "\n",
        "        # Converte as colunas de data para string se forem usadas como chave, para comparação consistente\n",
        "        if col in ['date', 'date_added', 'release_date']:\n",
        "            if col in df_existente.columns: # Apenas se a coluna realmente existe em df_existente\n",
        "                df_existente[col] = df_existente[col].astype(str)\n",
        "            tabela_nova[col] = tabela_nova[col].astype(str)\n",
        "\n",
        "    # --- Lógica de identificação de novos dados ---\n",
        "    if not df_existente.empty:\n",
        "        existing_keys = set(tuple(row[col] for col in key_columns) for _, row in df_existente[key_columns].iterrows())\n",
        "        df_novos_dados = tabela_nova[tabela_nova.apply(lambda row: tuple(row[col] for col in key_columns) not in existing_keys, axis=1)]\n",
        "        print(f\"Novas linhas identificadas para adição: {len(df_novos_dados)}\")\n",
        "    else:\n",
        "        df_novos_dados = tabela_nova\n",
        "        print(f\"Planilha existente vazia. Todas as {len(df_novos_dados)} linhas serão adicionadas como novas.\")\n",
        "\n",
        "    if not df_novos_dados.empty:\n",
        "        df_atualizado = pd.concat([df_existente, df_novos_dados], ignore_index=True)\n",
        "\n",
        "        # A remoção de duplicatas é feita agora após a concatenação, usando as key_columns\n",
        "        df_atualizado.drop_duplicates(subset=key_columns, inplace=True)\n",
        "        print(f\"Duplicatas removidas com base em {key_columns}.\")\n",
        "\n",
        "        # Garante que as colunas de data estejam no formato correto antes de enviar para o Sheets\n",
        "        if 'date' in df_atualizado.columns:\n",
        "            df_atualizado['date'] = pd.to_datetime(df_atualizado['date']).dt.strftime('%Y-%m-%d')\n",
        "        if 'date_added' in df_atualizado.columns:\n",
        "            df_atualizado['date_added'] = pd.to_datetime(df_atualizado['date_added']).dt.strftime('%Y-%m-%d')\n",
        "        if 'release_date' in df_atualizado.columns:\n",
        "            df_atualizado['release_date'] = pd.to_datetime(df_atualizado['release_date']).dt.strftime('%Y-%m-%d')\n",
        "\n",
        "        worksheet.clear()\n",
        "        set_with_dataframe(worksheet, df_atualizado)\n",
        "        print(f\"Planilha do Google Sheets '{sheet_name}' atualizada com sucesso com {len(df_novos_dados)} novas linhas.\")\n",
        "    else:\n",
        "        print(f\"Nenhum dado novo para atualizar na planilha '{sheet_name}'.\")\n",
        "\n",
        "# --- Configurações e Chamadas para cada tipo de dado ---\n",
        "\n",
        "# Audiência\n",
        "audience_folder = '/content/drive/MyDrive/dashboaddl/audiencia'\n",
        "audience_replacements = {\n",
        "    'Marina Melo-audience-timeline': 'Marina Melo',\n",
        "    'Preta Ary-audience-timeline': 'Preta Ary',\n",
        "    'Laura Lorenzetti-audience-timeline': 'Laura Lorenzetti',\n",
        "    'Bruni Chapow-audience-timeline': 'Bruni Chapow',\n",
        "    'Marissol Mwaba-audience-timeline': 'Marissol Mwaba',\n",
        "    'Jade Faria-audience-timeline': 'Jade Faria',\n",
        "    'Joana Castanheira-audience-timeline': 'Joana Castanheira',\n",
        "    'Rasura-audience-timeline': 'Rasura'\n",
        "}\n",
        "process_and_update_sheet(audience_folder, \"tabela_consolidada\", audience_replacements, key_cols_specific=['nome_arquivo_origem', 'date'])\n",
        "\n",
        "# Playlist 28 dias\n",
        "playlist28d_folder = '/content/drive/MyDrive/dashboaddl/p28d'\n",
        "playlist28d_replacements = {\n",
        "    'Joana Castanheira-playlists-28day': 'Joana Castanheira',\n",
        "    'Marina Melo-playlists-28day': 'Marina Melo',\n",
        "    'Jade Faria-playlists-28day': 'Jade Faria',\n",
        "    'Laura Lorenzetti-playlists-28day': 'Laura Lorenzetti',\n",
        "    'Marissol Mwaba-playlists-28day': 'Marissol Mwaba',\n",
        "    'Preta Ary-playlists-28day': 'Preta Ary',\n",
        "    'Rasura-playlists-28day': 'Rasura',\n",
        "    'Bruni Chapow-playlists-28day': 'Bruni Chapow'\n",
        "}\n",
        "process_and_update_sheet(playlist28d_folder, \"tabela28d\", playlist28d_replacements, key_cols_specific=['nome_arquivo_origem', 'title', 'date_added'])\n",
        "\n",
        "# Playlist 1 ano\n",
        "playlist1y_folder = '/content/drive/MyDrive/dashboaddl/p1an'\n",
        "playlist1y_replacements = {\n",
        "    'Joana Castanheira-playlists-1year': 'Joana Castanheira',\n",
        "    'Marina Melo-playlists-1year': 'Marina Melo',\n",
        "    'Marina Melo-playlists-1year (2)': 'Marina Melo',\n",
        "    'Jade Faria-playlists-1year': 'Jade Faria',\n",
        "    'Laura Lorenzetti-playlists-1year': 'Laura Lorenzetti',\n",
        "    'Marissol Mwaba-playlists-1year': 'Marissol Mwaba',\n",
        "    'Preta Ary-playlists-1year': 'Preta Ary',\n",
        "    'Rasura-playlists-1year': 'Rasura',\n",
        "    'Bruni Chapow-playlists-1year': 'Bruni Chapow'\n",
        "}\n",
        "process_and_update_sheet(playlist1y_folder, \"tabela1an\", playlist1y_replacements, key_cols_specific=['nome_arquivo_origem', 'title', 'date_added'])\n",
        "\n",
        "# Música 1 ano\n",
        "music1y_folder = '/content/drive/MyDrive/dashboaddl/musi1an'\n",
        "music1y_replacements = {\n",
        "    'Joana Castanheira-songs-1year': 'Joana Castanheira',\n",
        "    'Marina Melo-songs-1year': 'Marina Melo',\n",
        "    'Jade Faria-songs-1year': 'Jade Faria',\n",
        "    'Laura Lorenzetti-songs-1year': 'Laura Lorenzetti',\n",
        "    'Marissol Mwaba-songs-1year': 'Marissol Mwaba',\n",
        "    'Preta Ary-songs-1year': 'Preta Ary',\n",
        "    'Rasura-songs-1year': 'Rasura',\n",
        "    'Bruni Chapow-songs-1year': 'Bruni Chapow'\n",
        "}\n",
        "process_and_update_sheet(music1y_folder, \"tabelam1an\", music1y_replacements, key_cols_specific=['nome_arquivo_origem', 'song', 'release_date'])\n",
        "\n",
        "# Música 28 dias\n",
        "music28d_folder = '/content/drive/MyDrive/dashboaddl/musi28d'\n",
        "music28d_replacements = {\n",
        "    'Joana Castanheira-songs-28day': 'Joana Castanheira',\n",
        "    'Marina Melo-songs-28day': 'Marina Melo',\n",
        "    'Marina Melo-songs-28day (2)': 'Marina Melo',\n",
        "    'Jade Faria-songs-28day': 'Jade Faria',\n",
        "    'Laura Lorenzetti-songs-28day': 'Laura Lorenzetti',\n",
        "    'Marissol Mwaba-songs-28day': 'Marissol Mwaba',\n",
        "    'Preta Ary-songs-28day': 'Preta Ary',\n",
        "    'Rasura-songs-28day': 'Rasura',\n",
        "    'Bruni Chapow-songs-28day': 'Bruni Chapow'\n",
        "}\n",
        "process_and_update_sheet(music28d_folder, \"tabelam28d_s\", music28d_replacements, key_cols_specific=['nome_arquivo_origem', 'song', 'release_date'])"
      ]
    }
  ]
}